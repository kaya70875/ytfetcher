{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"YTFetcher","text":"<p>Build structured YouTube datasets at scale. Effortlessly fetch transcripts, metadata, and comments for NLP, ML, and AI workflows.</p>"},{"location":"#why-ytfetcher","title":"Why YTFetcher?","text":"<p>Most YouTube scrapers are either slow, break easily, or only give you raw text. YTFetcher is built for speed and structure:</p> <ul> <li>\ud83d\ude80 High performance: Fetches thousands of videos in minutes.</li> <li>\ud83d\udce6 Structured Data: Returns clean Pydantic models (metadata, transcripts, comments).</li> <li>\ud83d\udee0\ufe0f CLI &amp; API: Use it in your terminal or integrate it into your Python pipeline.</li> <li>\ud83d\udee1\ufe0f Built-in Proxy Support: Avoid rate limits with Generic or Webshare proxies.</li> <li>\ud83d\udcbe Export Options: Save results as JSON, CSV, or TXT formats.</li> <li>\ud83d\udcca Rich CLI Preview: Beautiful Rich tables for easy data inspection in terminal.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install ytfetcher\n</code></pre>"},{"location":"#basic-usage-python-api","title":"Basic Usage (Python API)","text":"<p>Here\u2019s how you can get transcripts and metadata information like channel name, description, published date, etc. from a channel with <code>from_channel</code> method: <pre><code>from ytfetcher import YTFetcher\n\nfetcher = YTFetcher.from_channel(\n    channel_handle=\"TheOffice\",\n    max_results=2\n)\n\nchannel_data = fetcher.fetch_youtube_data()\nprint(channel_data)\n</code></pre></p> <p>Tip</p> <p>Use <code>max_results=None</code> if you want to fetch all videos from a channel.</p> <p>Note</p> <p><code>ytfetcher</code> handles full channel url and channel handles without <code>@</code> symbol. So you can pass a full url like <code>https://www.youtube.com/@TheOffice</code> directly to terminal or to <code>channel_handle</code> parameter.</p> <p>This will return a list of <code>ChannelData</code> with metadata in <code>DLSnippet</code> objects: <pre><code>[\nChannelData(\n    video_id='video1',\n    transcripts=[\n        Transcript(\n            text=\"Hey there\",\n            start=0.0,\n            duration=1.54\n        ),\n        Transcript(\n            text=\"Happy coding!\",\n            start=1.56,\n            duration=4.46\n        )\n    ]\n    metadata=DLSnippet(\n        video_id='video1',\n        title='VideoTitle',\n        description='VideoDescription',\n        url='https://youtu.be/video1',\n        duration=120,\n        view_count=1000,\n        thumbnails=[{'url': 'thumbnail_url'}]\n    )\n),\n# Other ChannelData objects...\n]\n</code></pre></p>"},{"location":"#preview-data","title":"Preview Data","text":"<p>You can also preview this data using <code>PreviewRenderer</code> class from <code>ytfetcher.services</code>: <pre><code>from ytfetcher.services import PreviewRenderer\n\nchannel_data = fetcher.fetch_youtube_data(max_comments=10)\n#print(channel_data)\npreview = PreviewRenderer()\npreview.render(data=channel_data, limit=4)\n</code></pre></p> <p>This will preview the first 4 results of the data in a beautifully formatted terminal view, including metadata, transcript snippets, and comments.</p>"},{"location":"#using-different-fetchers","title":"Using Different Fetchers","text":"<p><code>ytfetcher</code> supports various fetching options that includes:</p> <ul> <li>Fetching from a playlist id with <code>from_playlist_id</code> method.</li> <li>Fetching from video id's with <code>from_video_ids</code> method.</li> <li>Fetching from a search query with <code>from_search</code> method.</li> </ul>"},{"location":"#fetching-from-playlist-id","title":"Fetching from Playlist ID","text":"<p>Use <code>from_playlist_id</code> to retrieve metadata and transcripts for every video within a public or unlisted YouTube playlist.</p> <pre><code>from ytfetcher import YTFetcher\n\nfetcher = YTFetcher.from_playlist_id(\n    playlist_id=\"playlistid1254\"\n)\n\n# Rest is same ...\n</code></pre>"},{"location":"#fetching-with-custom-video-ids","title":"Fetching With Custom Video IDs","text":"<p>If you already have specific video identifiers, <code>from_video_ids</code> allows you to target them directly. This is the most efficient way to fetch data when you have an external list of URLs or IDs.</p> <pre><code>from ytfetcher import YTFetcher\n\nfetcher = YTFetcher.from_video_ids(\n    video_ids=['video1', 'video2', 'video3']\n)\n\n# Rest is same ...\n</code></pre>"},{"location":"#fetching-with-search-query","title":"Fetching With Search Query","text":"<p>The <code>from_search</code> method allows you to discover videos based on a keyword or phrase, similar to using the YouTube search bar. You can control the breadth of the search using the <code>max_results</code> parameter.</p> <pre><code>from ytfetcher import YTFetcher\n\n# Searches for the top 10 videos matching 'Artificial Intelligence'\nfetcher = YTFetcher.from_search(\n    query=\"Artificial Intelligence\",\n    max_results=10\n)\n</code></pre> <p>Tip</p> <p>When using <code>from_search</code> with generic keywords (e.g., \"son\", \"gato\", \"gift\"), YouTube prioritizes results based on your geographic location (IP address). This can lead to transcripts in languages you didn't expect. To ensure you get the right content ensure your <code>YTFetcher</code> initialization includes the correct <code>language</code> parameter to match the expected transcript availability.</p>"},{"location":"#transcript-options","title":"Transcript Options","text":"<p>YTFetcher provides flexible transcript fetching with support for multiple languages and fallback mechanisms. You can customize how transcripts are retrieved to match your specific needs.</p>"},{"location":"#retrieve-different-languages","title":"Retrieve Different Languages","text":"<p>You can use the <code>languages</code> param to retrieve your desired language. (Default en)</p> <pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.config import FetchOptions\n\noptions = FetchOptions(\n    languages=[\"tr\", \"en\"]\n)\nfetcher = YTFetcher.from_video_ids(video_ids=video_ids, options=options)\n</code></pre> <p><code>ytfetcher</code> first tries to fetch the <code>Turkish</code> transcript. If it's not available, it falls back to <code>English</code>.</p>"},{"location":"#fetching-only-manually-created-transcripts","title":"Fetching Only Manually Created Transcripts","text":"<p><code>ytfetcher</code> allows you to fetch only manually created transcripts from a channel which allows you to get more precise transcripts. <pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.config import FetchOptions\nfetcher = YTFetcher.from_channel(channel_handle=\"TEDx\", options=FetchOptions(manually_created=True))\n</code></pre></p> <p>Note</p> <p>As default <code>ytfetcher</code> already tries to fetch manually created transcripts first, but if you want get only manually created ones you can use this flag.</p> <p>Tip</p> <p>Also it makes sense to use this flag to fetch channels like <code>TEDx</code> which naturally has more manually created transcripts.</p>"},{"location":"#filtering","title":"Filtering","text":"<p><code>ytfetcher</code> allows you to filter videos before fetching transcripts, which helps you focus on specific content and save processing time. Filters are applied to video metadata (duration, view count, title) and work with all fetcher methods.</p>"},{"location":"#available-filter-functions","title":"Available Filter Functions","text":"<p>The following filter functions are available in <code>ytfetcher.filters</code>:</p> <ul> <li><code>min_duration(sec: float)</code> - Filter videos with duration greater than or equal to specified seconds</li> <li><code>max_duration(sec: float)</code> - Filter videos with duration less than or equal to specified seconds</li> <li><code>min_views(n: int)</code> - Filter videos with view count greater than or equal to specified number</li> <li><code>max_views(n: int)</code> - Filter videos with view count less than or equal to specified number</li> <li><code>filter_by_title(search_query: str)</code> - Filter videos whose title contains the search query (case-insensitive)</li> </ul>"},{"location":"#using-filters-in-python-api","title":"Using Filters in Python API","text":"<p>Pass a list of filter functions to the <code>filters</code> parameter when creating a fetcher:</p> <pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.filters import min_duration, min_views, filter_by_title\nfrom ytfetcher.config import FetchOptions\n\noptions = FetchOptions(\n    filters=[\n        min_views(5000),\n        min_duration(600),  # At least 10 minutes\n        filter_by_title(\"tutorial\")\n    ]\n)\n\nfetcher = YTFetcher.from_channel(\n    channel_handle=\"TheOffice\",\n    max_results=50,\n    options=options\n)\n</code></pre>"},{"location":"#converting-channeldata-to-rows","title":"Converting ChannelData to Rows","text":"<p>If you want a flat, row-based structure for ML workflows (Pandas, HuggingFace datasets, JSON/Parquet), use the helper in <code>ytfetcher.utils</code> to join transcript segments. Comments are only included if you fetched them with <code>fetch_with_comments</code> or <code>fetch_comments</code>.</p> <pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.utils import channel_data_to_rows\n\nfetcher = YTFetcher.from_channel(channel_handle=\"TheOffice\", max_results=2)\nchannel_data = fetcher.fetch_with_comments(max_comments=5)\n\nrows = channel_data_to_rows(channel_data, include_comments=True)\n</code></pre>"},{"location":"#fetching-comments","title":"Fetching Comments","text":"<p><code>ytfetcher</code> allows you fetch comments in bulk with additional metadata and transcripts or just comments alone.</p> <p>Note</p> <p>Performance: Comment fetching is a resource-intensive process. The speed of extraction depends significantly on the user's internet connection and the total volume of comments being retrieved.</p>"},{"location":"#sqlite-cache","title":"SQLite Cache","text":"<p><code>ytfetcher</code> includes a built-in SQLite transcript cache to speed up repeated fetches.</p> <ul> <li>Enabled by default.</li> <li>Default location: <code>~/.cache/ytfetcher/cache.sqlite3</code>.</li> <li>Cache entries are keyed by <code>video_id</code> and transcript settings (<code>languages</code>, <code>manually_created</code>).</li> </ul>"},{"location":"#python-api","title":"Python API","text":"<pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.config import FetchOptions\n\noptions = FetchOptions(\n    cache_enabled=True,\n    cache_path=\"./.ytfetcher_cache\"\n)\n\nfetcher = YTFetcher.from_channel(\n    channel_handle=\"TheOffice\",\n    max_results=20,\n    options=options,\n)\n</code></pre> <p>Disable cache:</p> <pre><code>from ytfetcher.config import FetchOptions\n\noptions = FetchOptions(cache_enabled=False)\n</code></pre> <p>Control cache expiration with TTL (days):</p> <pre><code>from ytfetcher.config import FetchOptions\n\n# Keep cached transcripts for 3 days\noptions = FetchOptions(cache_ttl=3)\n\n# Disable expiration\noptions = FetchOptions(cache_ttl=0)\n</code></pre>"},{"location":"#fetch-comments-with-transcripts-and-metadata","title":"Fetch Comments With Transcripts And Metadata","text":"<p>To fetch comments alongside with transcripts and metadata you can use <code>fetch_with_comments</code> method.</p> <pre><code>fetcher = YTFetcher.from_channel(\"TheOffice\", max_results=5)\ncomments = fetcher.fetch_with_comments(max_comments=10, sort='top') # or new if you want latest comments\n</code></pre> <p>This will simply fetch top 10 comments for every video alongside with transcript data.</p> <p>Here's an example structure:</p> <pre><code>[\n    ChannelData(\n        video_id='id1',\n        transcripts=list[Transcript(...)],\n        metadata=DLSnippet(...),\n        comments=list[Comment(        \n            text='Comment one.',\n            like_count=20,\n            author='@author',\n            time_text='8 days ago'\n        )]\n    )\n]\n</code></pre>"},{"location":"#fetch-only-comments","title":"Fetch Only Comments","text":"<p>To fetch comments without transcripts you can use <code>fetch_comments</code> method. <pre><code>fetcher = YTFetcher.from_channel(\"TheOffice\", max_results=5)\ncomments = fetcher.fetch_comments(max_comments=20)\n</code></pre></p> <p>This will return list of <code>Comment</code> like this:</p> <pre><code>[\n    Comment(\n        text='Comment one.',\n        like_count=20,\n        author='@author',\n        time_text='8 days ago'\n    )\n\n    ## OTHER COMMENT OBJECTS...\n]\n</code></pre>"},{"location":"#proxy-and-configuration","title":"Proxy and Configuration","text":"<p>YTFetcher provides built-in support for proxy servers and custom HTTP configuration to help you avoid rate limits and customize request behavior when fetching YouTube data at scale.</p>"},{"location":"#proxy-configuration","title":"Proxy Configuration","text":"<p>When fetching large amounts of data, YouTube may rate limit your requests. Using a proxy helps distribute requests across different IP addresses, significantly reducing the risk of being blocked. YTFetcher supports two types of proxy configurations:</p> <p>Generic Proxy Configuration</p> <p>Use custom HTTP/HTTPS proxy servers with <code>GenericProxyConfig</code>:</p> <pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.config import GenericProxyConfig, FetchOptions\n\nproxy_config = GenericProxyConfig(\n    http_url=\"http://user:pass@host:port\",\n    https_url=\"https://user:pass@host:port\"\n)\n\nfetcher = YTFetcher.from_channel(\n    channel_handle=\"TheOffice\",\n    max_results=50,\n    options=FetchOptions(\n        proxy_config=proxy_config\n    )\n)\n</code></pre> <p>Webshare Proxy Configuration</p> <p>For Webshare proxy service users, use <code>WebshareProxyConfig</code>:</p> <pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.config import WebshareProxyConfig, FetchOptions\n\nproxy_config = WebshareProxyConfig(\n    proxy_username=\"your_webshare_username\",\n    proxy_password=\"your_webshare_password\"\n)\n\nfetcher = YTFetcher.from_channel(\n    channel_handle=\"TheOffice\",\n    max_results=50,\n    options=FetchOptions(\n        proxy_config=proxy_config\n    )\n)\n</code></pre> <p>Tip</p> <p>You can find your Webshare proxy credentials at https://dashboard.webshare.io/proxy/settings</p>"},{"location":"#http-configuration","title":"HTTP Configuration","text":"<p>YTFetcher automatically uses realistic browser-like headers to mimic real browser behavior. However, you can customize HTTP settings including custom headers:</p> <pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.config import HTTPConfig, FetchOptions\n\nhttp_config = HTTPConfig(\n    headers={\"User-Agent\": \"Custom-Agent/1.0\"}  # Custom headers\n)\n\nfetcher = YTFetcher.from_channel(\n    channel_handle=\"TheOffice\",\n    max_results=10,\n    options=FetchOptions(\n        http_config=http_config\n    )\n)\n</code></pre> <p>Note</p> <p>If you don't provide custom headers, YTFetcher will automatically use realistic browser headers to avoid detection.</p>"},{"location":"#progress-configurations","title":"Progress Configurations","text":"<p>By default, the <code>ytfetcher</code> Python API runs in silent mode to keep your logs clean. If you want to see real-time progress bars and status updates (similar to the CLI experience), you must explicitly enable verbose mode.</p> <p>Here's how to enable progress bars: <pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.utils.state import RuntimeConfig\n\n# 1. Enable verbose mode globally\nRuntimeConfig.enable_verbose()\n\n# 2. Run your fetch operations normally\n# Progress bars (tqdm) will now appear in your console\nfetcher = YTFetcher.from_channel(channel_handle=\"ChannelName\")\ndata = fetcher.fetch_youtube_data()\n</code></pre></p>"},{"location":"cli/","title":"YTFetcher CLI","text":"<p>Retrieve video transcripts and metadata from YouTube channels using the command-line interface.</p>"},{"location":"cli/#quick-start","title":"Quick Start","text":"<p>Fetch 50 video transcripts + metadata from a channel and save as JSON:</p> <pre><code>ytfetcher channel TheOffice -m 50 -f json\n</code></pre>"},{"location":"cli/#cli-overview","title":"CLI Overview","text":"<p>YTFetcher comes with a simple CLI so you can fetch data directly from your terminal. To see all available commands and options:</p> <pre><code>ytfetcher -h\n</code></pre> <p>YTFetcher supports three main commands:</p> <ul> <li><code>channel</code> - Fetch data from a YouTube channel handle</li> <li><code>video</code> - Fetch data from custom video IDs</li> <li><code>playlist</code> - Fetch data from a specific playlist ID</li> <li><code>search</code> - Fetch data based on a search query, similar to youtube search bar.</li> </ul>"},{"location":"cli/#commands","title":"Commands","text":""},{"location":"cli/#fetching-from-channel","title":"Fetching from Channel","text":"<p>Fetch transcripts and metadata from a YouTube channel:</p> <pre><code>ytfetcher channel &lt;CHANNEL_HANDLE&gt; -m &lt;MAX_RESULTS&gt; -f &lt;FORMAT&gt;\n</code></pre> <p>Required Arguments:</p> <p>-<code>channel</code> - YouTube channel handle (e.g., <code>TheOffice</code>)</p> <p>Optional Arguments:</p> <ul> <li><code>-m</code>, <code>--max-results</code> - Maximum number of videos to fetch (default: 20)</li> <li><code>--all</code> - Fetch ALL videos from a channel.</li> </ul> <p>Example:</p> <pre><code>ytfetcher channel TheOffice -m 20 -f json\n</code></pre> <p>Note</p> <p>You can use channel handles with or without the <code>@</code> symbol, or even full URLs like <code>https://www.youtube.com/@TheOffice</code>.</p>"},{"location":"cli/#fetching-from-video-ids","title":"Fetching from Video IDs","text":"<p>Fetch transcripts and metadata from specific video IDs:</p> <pre><code>ytfetcher video video_id1 video_id2 video_id3 -f &lt;FORMAT&gt;\n</code></pre> <p>Example:</p> <pre><code>ytfetcher video dQw4w9WgXcQ jNQXAC9IVRw -f csv\n</code></pre>"},{"location":"cli/#fetching-from-playlist-id","title":"Fetching from Playlist ID","text":"<p>Fetch transcripts and metadata from a YouTube playlist:</p> <pre><code>ytfetcher playlist &lt;PLAYLIST_ID&gt; -f &lt;FORMAT&gt;\n</code></pre> <p>Required Arguments:</p> <p>-<code>playlist</code> - YouTube playlist id.</p> <p>Optional Arguments:</p> <ul> <li><code>-m</code>, <code>--max-results</code> - Maximum number of videos to fetch (default: 20)</li> <li><code>--all</code> - Fetch ALL videos from a channel.</li> </ul> <p>Example:</p> <pre><code>ytfetcher playlist PLrAXtmRdnEQy6nuLMH7Pj4Lb3zY9gK8kK -f json -m 25\n</code></pre>"},{"location":"cli/#fetching-with-search-method","title":"Fetching With Search Method","text":"<p>Fetch transcripts and metadata based on a search query, similar to Youtube search.</p> <pre><code>ytfetcher search &lt;QUERY&gt; -m &lt;MAX_RESULTS&gt;\n</code></pre> <p>Example</p> <pre><code>ytfetcher search \"AI Getting Jobs\" -m 20 -f json\n</code></pre> <p>Tip</p> <p>When using <code>search</code> method with generic keywords (e.g., \"son\", \"gato\", \"gift\"), YouTube prioritizes results based on your geographic location (IP address). This can lead to transcripts in languages you didn't expect. To ensure you get the right content include <code>--languages</code> parameter to CLI with your desired languages.</p>"},{"location":"cli/#options","title":"Options","text":"<p>All commands support the following common options:</p>"},{"location":"cli/#transcript-options","title":"Transcript Options","text":"<p><code>--no-timing</code></p> <ul> <li>Exclude transcript timing information (start time and duration)</li> <li>Example: <code>ytfetcher channel TheOffice -f json --no-timing</code></li> </ul> <p><code>--languages</code></p> <ul> <li>Specify language codes in priority order (space-separated)</li> <li>Default: <code>en</code></li> <li>Example: <code>ytfetcher channel TheOffice -m 50 -f csv --languages tr en</code></li> <li>YTFetcher will try Turkish first, then fall back to English if unavailable</li> </ul> <p><code>--manually-created</code></p> <ul> <li>Fetch only videos with manually created transcripts (more accurate)</li> <li>Useful for channels like TEDx that have high-quality manual transcripts</li> <li>Example: <code>ytfetcher channel TEDx -f csv --manually-created</code></li> </ul> <p><code>--stdout</code></p> <ul> <li>Print data directly to console instead of exporting to file</li> <li>Example: <code>ytfetcher channel TheOffice --stdout</code></li> </ul> <p><code>--quiet</code></p> <ul> <li>Supress CLI logs and progress informations.</li> <li>Example: <code>ytfetcher channel TEDx --quiet</code></li> </ul>"},{"location":"cli/#comment-options","title":"Comment Options","text":"<p><code>--comments &lt;NUMBER&gt;</code></p> <ul> <li>Fetch top N comments alongside transcripts and metadata</li> <li>Example: <code>ytfetcher channel TheOffice -m 20 --comments 10 -f json</code></li> <li>This fetches top 10 comments for each video along with transcripts</li> </ul> <p><code>--comments-only &lt;NUMBER&gt;</code></p> <ul> <li>Fetch only comments with metadata (no transcripts)</li> <li>Example: <code>ytfetcher channel TheOffice -m 20 --comments-only 10 -f json</code></li> </ul> <p><code>--sort</code> &lt;<code>top</code>, <code>new</code>&gt;</p> <ul> <li>Sort comments with top or newest ones (default to <code>top</code>).</li> <li>Example: <code>ytfetcher channel TheOffice -m 10 -c --sort new</code></li> </ul> <p>Warning</p> <p>Comment fetching is resource-intensive. Performance depends on your internet connection and the volume of comments being retrieved.</p>"},{"location":"cli/#filtering-options","title":"Filtering Options","text":"<p>Filters are applied before fetching transcripts, allowing you to focus on specific content and save processing time. Multiple filters use AND logic - all specified filters must pass for a video to be included.</p> <p><code>--min-views &lt;NUMBER&gt;</code></p> <ul> <li>Filter videos with view count greater than or equal to the specified number</li> <li>Example: <code>ytfetcher channel TheOffice -m 50 -f json --min-views 1000</code></li> <li>Only processes videos with at least 1000 views</li> </ul> <p><code>--min-duration &lt;SECONDS&gt;</code></p> <ul> <li>Filter videos with duration greater than or equal to the specified seconds</li> <li>Example: <code>ytfetcher channel TheOffice -m 50 -f csv --min-duration 300</code></li> <li>Only processes videos that are at least 5 minutes (300 seconds) long</li> </ul> <p><code>--includes-title &lt;STRING&gt;</code></p> <ul> <li>Filter videos whose title contains the specified string (case-insensitive)</li> <li>Example: <code>ytfetcher channel TheOffice -m 50 -f json --includes-title \"episode\"</code></li> <li>Only processes videos with \"episode\" in the title</li> </ul> <p>Combining Multiple Filters</p> <p>You can combine multiple filters to create more specific criteria:</p> <pre><code>ytfetcher channel TheOffice -m 50 -f json \\\n  --min-views 1000 \\\n  --min-duration 300 \\\n  --includes-title \"tutorial\"\n</code></pre> <p>This command only processes videos that:</p> <ul> <li>Have at least 1000 views</li> <li>Are at least 5 minutes long</li> <li>Have \"tutorial\" in the title</li> </ul> <p>Note</p> <p>Filters work on video metadata retrieved before transcript fetching. If a video's metadata is missing (e.g., <code>duration=None</code>), it will be excluded by duration filters.</p>"},{"location":"cli/#cache-options","title":"Cache Options","text":"<p><code>--no-cache</code></p> <ul> <li>Disable SQLite transcript cache for this run</li> <li>Useful when you explicitly want fresh transcript fetches</li> <li>Example: <code>ytfetcher channel TheOffice -m 20 --no-cache -f json</code></li> </ul> <p><code>--cache-path</code></p> <ul> <li>Set custom cache directory (the file <code>cache.sqlite3</code> is created inside this directory)</li> <li>Default: <code>~/.cache/ytfetcher</code></li> <li>Example: <code>ytfetcher channel TheOffice -m 20 --cache-path ./my_cache -f json</code></li> </ul> <p><code>--cache-ttl</code></p> <ul> <li>Cache expiration time in days</li> <li>Default: <code>7</code></li> <li>Use <code>0</code> to disable automatic expiration</li> <li>Example: <code>ytfetcher channel TheOffice -m 20 --cache-ttl 3 -f json</code></li> </ul> <p><code>ytfetcher cache --clean</code></p> <ul> <li>Clear all cached transcript rows</li> <li>Example: <code>ytfetcher cache --clean</code></li> <li>Custom path example: <code>ytfetcher cache --clean --cache-path ./my_cache</code></li> </ul>"},{"location":"cli/#export-options","title":"Export Options","text":"<p><code>-f</code>, <code>--format</code></p> <ul> <li>Export format: <code>txt</code>, <code>json</code>, or <code>csv</code></li> <li>Example: <code>ytfetcher channel TheOffice -f csv</code></li> </ul> <p><code>--metadata</code></p> <ul> <li>Specify which metadata fields to include (space-separated)</li> <li>Available options: <code>title</code>, <code>description</code>, <code>url</code>, <code>duration</code>, <code>view_count</code>, <code>thumbnails</code></li> <li>Default: All metadata fields</li> <li>Example: <code>ytfetcher channel TheOffice -m 20 -f json --metadata title description</code></li> </ul> <p><code>-o</code>, <code>--output-dir</code></p> <ul> <li>Output directory for exported files</li> <li>Default: Current directory (<code>.</code>)</li> <li>Example: <code>ytfetcher channel TheOffice -f json -o ./exports</code></li> </ul> <p><code>--filename</code></p> <ul> <li>Custom filename for exported data</li> <li>Default: <code>data</code></li> <li>Example: <code>ytfetcher channel TheOffice -f json --filename my_videos</code></li> </ul>"},{"location":"cli/#proxy-options","title":"Proxy Options","text":"<p><code>--http-proxy</code> and <code>--https-proxy</code></p> <ul> <li>Use custom HTTP/HTTPS proxy servers</li> <li>Example: <code>ytfetcher channel TheOffice -f json --http-proxy \"http://user:pass@host:port\" --https-proxy \"https://user:pass@host:port\"</code></li> </ul> <p><code>--webshare-proxy-username</code> and <code>--webshare-proxy-password</code></p> <ul> <li>Use Webshare proxy service</li> <li>Get credentials from Webshare Dashboard</li> <li>Example: <code>ytfetcher channel TheOffice -f json --webshare-proxy-username \"your_username\" --webshare-proxy-password \"your_password\"</code></li> </ul> <p><code>--http-timeout</code></p> <ul> <li>HTTP request timeout in seconds</li> <li>Default: <code>4.0</code></li> <li>Example: <code>ytfetcher channel TheOffice --http-timeout 6.0</code></li> </ul> <p><code>--http-headers</code></p> <ul> <li>Custom HTTP headers (Python dictionary format)</li> <li>Example: <code>ytfetcher channel TheOffice --http-headers \"{'User-Agent': 'Custom-Agent/1.0'}\"</code></li> </ul>"},{"location":"cli/#complete-examples","title":"Complete Examples","text":""},{"location":"cli/#basic-export-with-custom-metadata","title":"Basic Export with Custom Metadata","text":"<pre><code>ytfetcher channel TheOffice -m 20 -f json --no-timing --metadata title description\n</code></pre> <p>This command:</p> <ul> <li>Fetches 20 videos from TheOffice channel</li> <li>Exports as JSON</li> <li>Excludes transcript timings</li> <li>Includes only title and description metadata</li> </ul>"},{"location":"cli/#fetch-comments-with-transcripts","title":"Fetch Comments with Transcripts","text":"<pre><code>ytfetcher channel TheOffice -m 10 --comments 5 -f csv -o ./data\n</code></pre> <p>This command:</p> <ul> <li>Fetches 10 videos</li> <li>Includes top 5 comments per video</li> <li>Exports as CSV</li> <li>Saves to <code>./data</code> directory</li> </ul>"},{"location":"cli/#multi-language-transcripts","title":"Multi-language Transcripts","text":"<pre><code>ytfetcher channel TheOffice -m 50 -f json --languages es en fr\n</code></pre> <p>This command:</p> <ul> <li>Tries Spanish transcripts first</li> <li>Falls back to English if Spanish unavailable</li> <li>Falls back to French if English unavailable</li> </ul>"},{"location":"cli/#using-proxy-for-rate-limit-avoidance","title":"Using Proxy for Rate Limit Avoidance","text":"<pre><code>ytfetcher channel TheOffice -m 100 -f json \\\n  --webshare-proxy-username \"your_username\" \\\n  --webshare-proxy-password \"your_password\"\n</code></pre> <p>This command uses Webshare proxy to avoid rate limits when fetching large amounts of data.</p>"},{"location":"cli/#export-only-comments","title":"Export Only Comments","text":"<pre><code>ytfetcher channel TheOffice -m 20 --comments-only 15 -f json --filename comments_only\n</code></pre> <p>This command fetches only comments (no transcripts) and saves them to <code>comments_only.json</code>.</p>"},{"location":"cli/#output-behavior","title":"Output Behavior","text":"<p>By default, YTFetcher shows a preview of the first 5 results in your terminal. To see the full output:</p> <ul> <li>Use <code>--stdout</code> to print all data to console</li> <li>Use <code>-f</code> or <code>--format</code> to export to a file (JSON, CSV, or TXT)</li> </ul> <p>If you specify both <code>--format</code> and <code>--stdout</code>, the data will be both exported and printed to console.</p>"},{"location":"examples/","title":"Example Use Cases","text":"<p>We created example use cases for you. You can check and get inspired by visiting our GitHub repository.</p>"},{"location":"examples/#searching-for-keywords-in-channel-transcripts","title":"Searching for Keywords in Channel Transcripts","text":"<p>One common use case is searching for specific keywords or phrases across all videos in a channel. Here's an example:</p> <pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.services import JSONExporter\n\ndef search_in_channel(handle: str, keyword: str):\n    # 1. Initialize using your factory method\n    fetcher = YTFetcher.from_channel(\n        channel_handle=handle,\n        max_results=5\n    )\n\n    # 2. Fetch the structured data\n    print(f\"Searching for '{keyword}' in @{handle}...\")\n    channel_data = fetcher.fetch_youtube_data()\n\n    matches = []\n\n    # 3. Iterate through your ChannelData models\n    for video in channel_data:\n        for entry in video.transcripts:\n            if keyword.lower() in entry.text.lower():\n                matches.append({\n                    \"video_id\": video.video_id,\n                    \"timestamp\": entry.start,\n                    \"text\": entry.text\n                })\n\n    # 4. Show off the results\n    print(f\"Found {len(matches)} matches!\")\n    for m in matches[:5]: # Show first 5\n        print(f\"[{m['timestamp']}s] in {m['video_id']}: {m['text']}\")\n\n    # 5. Use your JSONExporter to save the findings\n    exporter = JSONExporter(\n        channel_data=channel_data,\n        filename=f\"{keyword}_search_results\",\n        timing=True\n    )\n    exporter.write()\n\nif __name__ == \"__main__\":\n    search_in_channel(\"TheOffice\", \"Dunder Mifflin\")\n</code></pre>"},{"location":"examples/#sentiment-analysis-with-youtube-comments","title":"Sentiment Analysis With Youtube Comments","text":"<p>We can use <code>fetch_with_comments</code> method to get top comments and use it for sentiment analysis.</p> <p>First install <code>vaderSentiment</code> for analysis.</p> <pre><code>pip install vaderSentiment\n</code></pre> <p>Here's the full code:</p> <pre><code>from ytfetcher import YTFetcher\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\ndef analyze_comments(handle: str):\n    # 1. Initialize the fetcher for a specific channel\n    fetcher = YTFetcher.from_channel(channel_handle=handle, max_results=3)\n\n    # 2. Fetch data WITH comments (using your specific method)\n    print(f\"Fetching comments from @{handle}...\")\n    channel_data = fetcher.fetch_with_comments(max_comments=20)\n\n    analyzer = SentimentIntensityAnalyzer()\n    stats = {\"Positive\": 0, \"Neutral\": 0, \"Negative\": 0}\n\n    # 3. Process the data\n    for video in channel_data:\n        print(f\"\\n--- Analyzing: {video.video_id} ---\")\n\n        if not video.comments:\n            print(\"No comments found for this video.\")\n            continue\n\n        for comment in video.comments:\n            # Use comment.text as defined in your Comment model\n            scores = analyzer.polarity_scores(comment.text)\n            compound = scores['compound']\n\n            if compound &gt;= 0.05:\n                sentiment = \"Positive\"\n            elif compound &lt;= -0.05:\n                sentiment = \"Negative\"\n            else:\n                sentiment = \"Neutral\"\n\n            stats[sentiment] += 1\n            print(f\"[{sentiment}] {comment.author}: {comment.text[:50]}...\")\n\n    # 4. Final Summary\n    print(\"\\n\" + \"=\"*30)\n    print(f\"OVERALL SENTIMENT FOR @{handle}\")\n    for label, count in stats.items():\n        print(f\"{label}: {count}\")\n\nif __name__ == \"__main__\":\n    analyze_comments(\"TheOffice\")\n</code></pre>"},{"location":"examples/#the-ai-ready-content-summarizer","title":"The AI-Ready Content Summarizer","text":"<p>This script fetches a video's transcript, strips out unnecessary timing info, and combines it with metadata to create a perfectly formatted <code>.txt</code> file that you can drop into any AI tool.</p> <pre><code>from ytfetcher import YTFetcher\nfrom ytfetcher.services import TXTExporter\n\ndef prepare_for_ai(video_ids: list[str]):\n    # 1. Initialize using the video URL factory\n    fetcher = YTFetcher.from_video_ids(video_ids=video_ids)\n\n    print(f\"Downloading transcript for AI processing...\")\n    channel_data = fetcher.fetch_youtube_data()\n\n    # 2. Extract the text only for a clean 'context' string\n    full_transcript = \"\"\n    for video in channel_data:\n        # We join the transcript segments into one clean block of text\n        full_transcript = \" \".join([t.text for t in video.transcripts])\n        title = video.metadata.title if video.metadata else \"Unknown Title\"\n\n    # 3. Use your TXTExporter with specific settings \n    # We turn off 'timing' to make it readable for an AI\n    exporter = TXTExporter(\n        channel_data=channel_data,\n        filename=\"ai_context_ready\",\n        timing=False, \n        allowed_metadata_list=['title', 'url', 'description']\n    )\n    exporter.write()\n\n    print(f\"--- PREVIEW FOR AI ---\")\n    print(f\"Title: {title}\")\n    print(f\"Transcript Length: {len(full_transcript)} characters\")\n    print(f\"File saved to: ./exports/ai_context_ready.txt\")\n\nif __name__ == \"__main__\":\n    url = ['NKnZYvZA7w4']\n    prepare_for_ai(url)\n</code></pre>"},{"location":"exporting/","title":"Exporting","text":"<p>The exporting feature allows you to save channel data in multiple formats for analysis, reporting, or integration with other tools. <code>ytfetcher</code> supports three widely-used export formats to suit different use cases and preferences.</p> <p>Use the <code>BaseExporter</code> class to export <code>ChannelData</code> in csv, json, or txt:</p> <pre><code>from ytfetcher.services import JSONExporter # OR you can import other exporters: TXTExporter, CSVExporter\n\nchannel_data = fetcher.fetch_youtube_data()\n\nexporter = JSONExporter(\n    channel_data=channel_data,\n    allowed_metadata_list=['title'],\n    timing=True,\n    filename='my_export',\n    output_dir='./exports'\n)\n\nexporter.write()\n</code></pre>"},{"location":"exporting/#exporter-parameters","title":"Exporter Parameters","text":"Parameter Type Description <code>channel_data</code> <code>ChannelData</code> The channel data object to export (required) <code>allowed_metadata_list</code> <code>list[str]</code> List of metadata fields to include in the export. Common fields: <code>title</code>, <code>description</code>, <code>duration</code>, <code>upload_date</code>, etc. <code>timing</code> <code>bool</code> Whether to include transcript timing information (start time and duration for each segment) <code>filename</code> <code>str</code> Base filename for the exported file (without extension) <code>output_dir</code> <code>str</code> Directory path where the exported file will be saved. Defaults to current directory if not specified"},{"location":"exporting/#example-with-different-metadata","title":"Example with Different Metadata","text":"<pre><code># Export with more metadata fields\nexporter = CSVExporter(\n    channel_data=channel_data,\n    allowed_metadata_list=['title', 'duration', 'upload_date', 'view_count'],\n    timing=False,\n    filename='channel_analysis',\n    output_dir='./data/exports'\n)\n\nexporter.write()\n</code></pre>"},{"location":"exporting/#custom-exporters-advanced","title":"Custom Exporters (Advanced)","text":"<p>If you need to support a format not provided by <code>ytfetcher</code> (like XML), you can extend the <code>BaseExporter</code> class. You only need to implement the <code>write()</code> method. <pre><code>from ytfetcher.services import BaseExporter\n\nclass XMLExporter(BaseExporter):\n    def write(self):\n        output_path = self._initialize_output_path(export_type='xml')\n        # Your custom logic to convert self.channel_data to XML\n        print(f\"Exporting data to {output_path}\")\n</code></pre></p>"},{"location":"release-notes/","title":"Release Notes","text":""},{"location":"release-notes/#latest-changes","title":"Latest Changes","text":""},{"location":"release-notes/#added","title":"Added","text":"<ul> <li>Introduced a new <code>FetchOptions</code> data class for defining fetcher options like <code>languages</code>, <code>filters</code> etc.</li> <li>Added a <code>--sort</code> argument for choosing top or new comments with CLI.</li> <li>Added <code>from_search</code> method for both Python API and CLI. This method allows user to fetch based on a <code>query</code>, similar to Youtube search.</li> <li>Added a <code>--quiet</code> tag for CLI.</li> <li>Added pre-fetch filters for <code>ytfetcher</code>.</li> </ul>"},{"location":"release-notes/#changed","title":"Changed","text":"<ul> <li>Removed deprecated <code>Exporter</code> class.</li> <li>No more network requests in init.</li> <li><code>YTFetcher</code> now initializes correct <code>BaseYoutubeDLFetcher</code> inside classmethods.</li> <li><code>TranscriptFetcher</code> creates <code>Session</code> per thread for thread safety.</li> <li><code>TranscripFetcher</code> now returns <code>VideoTranscript</code> instead of returning <code>ChannelData</code>.</li> <li><code>Exporter</code> class now do not write <code>None</code> values to file which reduces total file size and noise.</li> <li>Changed main CLI arguments for easier usage and user experience.</li> <li>Python API for <code>ytfetcher</code> is now completely silent as default. Logs and progress informations are only visible in CLI or by enabling <code>verbose</code> mode.</li> <li>Changed <code>ytfetcher</code> to be completely sync.</li> </ul>"},{"location":"release-notes/#fixed","title":"Fixed","text":"<ul> <li>Fixed a very critical bug that metadata, transcripts and comments are not aligned.</li> <li>Fixed <code>HTTPConfig</code> class <code>InvalidHeader</code> check.</li> <li>Fixed VideoListFetcher performance issue with implementing <code>ThreadPoolExecutor</code>.</li> <li>Fixed <code>CommentFetcher</code> doesn't fetch top comments.</li> </ul>"},{"location":"release-notes/#153-2026-01-01","title":"[1.5.3] - 2026-01-01","text":""},{"location":"release-notes/#added_1","title":"Added","text":"<ul> <li>Added preview mode in CLI for <code>ytfetcher</code>. It's now default mode and exporting is optional with <code>--format</code>. Also dumping data possible with <code>--stdout</code> argument in CLI.</li> </ul>"},{"location":"release-notes/#changed_1","title":"Changed","text":"<ul> <li>Exporter now optional in CLI if you don't define <code>--format</code> argument.</li> <li>Categorized <code>ytfetcher</code> arguments for better clarity and user experience.</li> </ul>"},{"location":"release-notes/#15-2025-12-31","title":"[1.5] - 2025-12-31","text":""},{"location":"release-notes/#added_2","title":"Added","text":"<ul> <li>Added comment fetching feature. You can now fetch comments alongside with transcript data or fetch comments only.</li> <li>Added <code>Dockerfile</code> and <code>docker-compose.yml</code> for setup docker enviroment.</li> </ul>"},{"location":"release-notes/#changed_2","title":"Changed","text":"<ul> <li><code>Exporter</code> changed to subclasses; <code>JSONExporter</code>, <code>TXTExporter</code> and <code>CSVExporter</code> for better control over every export option.</li> <li>Changed some log messages to be more professional and clear.</li> </ul>"},{"location":"release-notes/#fixed_1","title":"Fixed","text":"<ul> <li>Fix KeyError for missing 'url' in yt_dlp entry when fetching by video_ids.</li> </ul>"},{"location":"release-notes/#14-2025-10-26","title":"[1.4] - 2025-10-26","text":""},{"location":"release-notes/#added_3","title":"Added","text":"<ul> <li>Added a flag for fetching only manually created transcripts.</li> </ul>"},{"location":"release-notes/#fixed_2","title":"Fixed","text":"<ul> <li>Transcript cleaner method does not clean <code>&gt;&gt;</code> signs.</li> </ul>"},{"location":"release-notes/#13-2025-18-10","title":"[1.3] - 2025-18-10","text":""},{"location":"release-notes/#added_4","title":"Added","text":"<ul> <li>Add <code>PlaylistFetcher</code> for CLI and Python API.</li> <li>Add metadata choosing option for CLI.</li> <li>Add <code>no-timing</code> argument for CLI for not choosing transcript timings.</li> <li>Full url support for <code>PlaylistFetcher</code> and <code>ChannelFetcher</code>.</li> </ul>"},{"location":"release-notes/#changed_3","title":"Changed","text":"<ul> <li>Exporter now exports all available data as default.</li> </ul>"},{"location":"release-notes/#12-2025-11-10","title":"[1.2] - 2025-11-10","text":""},{"location":"release-notes/#added_5","title":"Added","text":"<ul> <li>Users now can choose desired language for transcripts.</li> <li>Added progressive print statements for <code>CLI</code></li> <li>Added more logging statements for better debug and information.</li> </ul>"},{"location":"release-notes/#changed_4","title":"Changed","text":"<ul> <li>(docs) Add documentation for choosing primary transcript language.</li> </ul>"},{"location":"release-notes/#fixed_3","title":"Fixed","text":"<ul> <li>Removed load_env module from <code>python-dotenv</code> in <code>config.__init__</code> since it removed.</li> </ul>"},{"location":"release-notes/#11-2025-10-02","title":"[1.1] - 2025-10-02","text":""},{"location":"release-notes/#added_6","title":"Added","text":"<ul> <li>Add progress bar support to from_video_ids method for YoutubeDL.</li> <li>Add print arg for allow users to print data to console.</li> <li>TranscriptFetcher now cleans transcripts that includes texts like <code>[Music]</code>, <code>[Applause]</code> etc.</li> <li>Add official documentation website for ytfetcher.</li> </ul>"},{"location":"release-notes/#101-2025-10-01","title":"[1.0.1] - 2025-10-01","text":""},{"location":"release-notes/#added_7","title":"Added","text":"<ul> <li>(docs) Add cli help output to readme.</li> </ul>"},{"location":"release-notes/#changed_5","title":"Changed","text":"<ul> <li>Updated package dependencies.</li> </ul>"},{"location":"release-notes/#fixed_4","title":"Fixed","text":"<ul> <li><code>from_video_ids</code> method does not work both in CLI and python API.</li> </ul>"},{"location":"release-notes/#10-2025-09-27","title":"[1.0] - 2025-09-27","text":""},{"location":"release-notes/#added_8","title":"Added","text":"<ul> <li>Ytfetcher now runs without an api key.</li> <li>Added YoutubeDL for fetching video id's and snippets faster and without requiring an API key.</li> </ul>"},{"location":"release-notes/#changed_6","title":"Changed","text":"<ul> <li>Removed YoutubeV3 class since YoutubeDL is simpler and faster.</li> <li>Changed readme accordingly based on last changes.</li> </ul>"},{"location":"release-notes/#041-2025-08-10","title":"[0.4.1] - 2025-08-10","text":""},{"location":"release-notes/#added_9","title":"Added","text":"<ul> <li>Add instructions to docs for how to find channel_handle and change <code>channel_name</code> args with <code>&lt;CHANNEL_HANDLE&gt;</code> for better clarity.</li> <li>Add quick usage section in README.</li> </ul>"},{"location":"release-notes/#040-2025-08-10","title":"[0.4.0] - 2025-08-10","text":""},{"location":"release-notes/#added_10","title":"Added","text":"<ul> <li>Users now can save their api keys with <code>ytfetcher config &lt;API_KEY&gt;</code> once and use it globally without writing everytime while using CLI.</li> </ul>"},{"location":"release-notes/#030-2025-08-09","title":"[0.3.0] - 2025-08-09","text":""},{"location":"release-notes/#added_11","title":"Added","text":"<ul> <li>Add filename support for exporing data in CLI.</li> <li>Add thumbnail details to ChannelData Export.</li> </ul>"},{"location":"release-notes/#changed_7","title":"Changed","text":"<ul> <li>Make thumbnail metadata default.</li> </ul>"},{"location":"release-notes/#021-2025-08-08","title":"[0.2.1] - 2025-08-08","text":""},{"location":"release-notes/#changed_8","title":"Changed","text":"<ul> <li>Change default timeout to <code>null</code> for HTTPConfig class.</li> </ul>"},{"location":"release-notes/#020-2025-08-07","title":"[0.2.0] - 2025-08-07","text":""},{"location":"release-notes/#added_12","title":"Added","text":"<ul> <li>Add tags and classifiers to pyproject.toml.</li> <li>Add issue templates for bug reports and feature requests.</li> <li>Add docs for http config in CLI.</li> </ul>"},{"location":"release-notes/#changed_9","title":"Changed","text":"<ul> <li>Update youtube-transcript-api 1.1.1 to 1.2.1</li> </ul>"},{"location":"release-notes/#011-2025-08-03","title":"[0.1.1] - 2025-08-03","text":""},{"location":"release-notes/#added_13","title":"Added","text":"<ul> <li>Add Custom <code>http-timeout</code> and <code>http-headers</code> options for CLI.</li> </ul>"},{"location":"release-notes/#fixed_5","title":"Fixed","text":"<ul> <li>Video ids doesn't work with <code>from_video_ids</code> method in CLI.</li> </ul>"},{"location":"release-notes/#changed_10","title":"Changed","text":"<ul> <li>HTTPConfig now takes <code>float</code> as timeout paramater instead of <code>httpx.Timeout</code> which causes unnecessary complexity.</li> </ul>"},{"location":"release-notes/#010-2025-08-03","title":"[0.1.0] - 2025-08-03","text":""},{"location":"release-notes/#added_14","title":"Added","text":"<ul> <li>Initial release: CLI to fetch and export YouTube transcripts</li> </ul>"},{"location":"release-notes/#changed_11","title":"Changed","text":"<ul> <li>Update docs for <code>get_metadata</code> method.</li> <li>Change default httpx.Timeout value to 4.0 to 2.0.</li> </ul>"}]}